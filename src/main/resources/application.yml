spring:
  application:
    name: databaseevent
  jpa:
    database-platform: org.hibernate.dialect.H2Dialect
    database: H2
    show_sql: true
#    generate-ddl: true
    properties:
      hibernate:
        format_sql: true # To beautify or pretty print the SQL
#        ddl-auto: validate # not to overwrite my schema (if you had schema.sql scripts). Usually hibernate looks at the entities and generates schema based on those entities
        ddl-auto: create
  datasource:
    url: jdbc:h2:mem:mydb
    username: sa
    password: password
    driverClassName: org.h2.Driver
  h2:
    console:
      enabled: true
      path: /h2-console # URL to access this console http://localhost:9006/databaseevent/h2-console. Change the JDBC URL to whats above and login with sa/password
      settings:
        trace: false
        web-allow-others: false
  cloud:
    stream:
      bindings:
        inbound-in-0:
          contentType: application/*+avro
          destination: customer-inbound-topic
          group: customer-inbound-only-group
          consumer:
            useNativeDecoding: true
        process-in-0:
          contentType: application/*+avro
          destination: customer-inbound-topic
          group: customer-inbound-group
          consumer:
            useNativeDecoding: true
        process-out-0:
          contentType: application/*+avro
          destination: customer-outbound-topic
          producer:
            useNativeDecoding: true
        outbound-out-0:
          binder: kafka
          contentType: application/*+avro
          destination: customer-outbound-topic
          producer:
            useNativeEncoding: true

      kafka:
        binder:
          brokers: localhost:9092
          autoCreateTopics: false

        bindings:
          outbound-out-0:
            producer:
              configuration:
                key.serializer: org.apache.kafka.common.serialization.StringSerializer
                value.serializer: io.confluent.kafka.serializers.KafkaAvroSerializer
                schema:
                  registry:
                    url: http://localhost:8081
                    headers.x-api-key: 12345
                auto.register.schemas: false
                use.latest.version: true
#                use.schema.id: 1

        streams:
          binder:
            brokers: localhost:9092
            autoCreateTopics: false
            configuration:
              schema.registry.url: http://localhost:8081

          bindings:
            inbound-in-0:
              consumer:
                applicationId: customer-inbound-only-group
                keySerde: org.apache.kafka.common.serialization.Serdes$StringSerde
                valueSerde: io.confluent.kafka.streams.serdes.avro.SpecificAvroSerde
            process-in-0:
              ackMode: MANUAL
              consumer:
                applicationId: customer-inbound-group
                keySerde: org.apache.kafka.common.serialization.Serdes$StringSerde
                valueSerde: io.confluent.kafka.streams.serdes.avro.SpecificAvroSerde
            process-out-0:
              producer:
                contentType: application/*+avro
                keySerde: org.apache.kafka.common.serialization.Serdes$StringSerde
                valueSerde: io.confluent.kafka.streams.serdes.avro.SpecificAvroSerde


application:
  name: databaseevent

logging:
  level:
    org.springframework: DEBUG

server:
  port: 9006
  servlet:
    context-path: /databaseevent

management:
  endpoint:
    health:
      show-details: ALWAYS
  endpoints:
    web:
      base-path: /
